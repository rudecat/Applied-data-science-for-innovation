{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "pycharm-1c32425b",
   "display_name": "PyCharm (Machine+Learning+A-Z+(Codes+and+Datasets))"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "source": [
    "## Assignment-B Multivariant Linear Regression\n",
    "@author: Kai-Ping Wang"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "## Importing the libraries\n",
    "Import all required libraries, and also set some libraries options."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "pd.set_option('display.max_columns', None)"
   ]
  },
  {
   "source": [
    "## Importing the dataset"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_url = 'https://raw.githubusercontent.com/aso-uts/applied_ds/master/assignment1/cancer_reg.csv'\n",
    "df = pd.read_csv(file_url, encoding='ISO-8859-1')"
   ]
  },
  {
   "source": [
    "## Checking the dataset\n",
    "Check the data structure and information to be sure if data processing is required"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\nRangeIndex: 3047 entries, 0 to 3046\nData columns (total 34 columns):\n #   Column                   Non-Null Count  Dtype  \n---  ------                   --------------  -----  \n 0   avgAnnCount              3047 non-null   float64\n 1   avgDeathsPerYear         3047 non-null   int64  \n 2   TARGET_deathRate         3047 non-null   float64\n 3   incidenceRate            3047 non-null   float64\n 4   medIncome                3047 non-null   int64  \n 5   popEst2015               3047 non-null   int64  \n 6   povertyPercent           3047 non-null   float64\n 7   studyPerCap              3047 non-null   float64\n 8   binnedInc                3047 non-null   object \n 9   MedianAge                3047 non-null   float64\n 10  MedianAgeMale            3047 non-null   float64\n 11  MedianAgeFemale          3047 non-null   float64\n 12  Geography                3047 non-null   object \n 13  AvgHouseholdSize         3047 non-null   float64\n 14  PercentMarried           3047 non-null   float64\n 15  PctNoHS18_24             3047 non-null   float64\n 16  PctHS18_24               3047 non-null   float64\n 17  PctSomeCol18_24          762 non-null    float64\n 18  PctBachDeg18_24          3047 non-null   float64\n 19  PctHS25_Over             3047 non-null   float64\n 20  PctBachDeg25_Over        3047 non-null   float64\n 21  PctEmployed16_Over       2895 non-null   float64\n 22  PctUnemployed16_Over     3047 non-null   float64\n 23  PctPrivateCoverage       3047 non-null   float64\n 24  PctPrivateCoverageAlone  2438 non-null   float64\n 25  PctEmpPrivCoverage       3047 non-null   float64\n 26  PctPublicCoverage        3047 non-null   float64\n 27  PctPublicCoverageAlone   3047 non-null   float64\n 28  PctWhite                 3047 non-null   float64\n 29  PctBlack                 3047 non-null   float64\n 30  PctAsian                 3047 non-null   float64\n 31  PctOtherRace             3047 non-null   float64\n 32  PctMarriedHouseholds     3047 non-null   float64\n 33  BirthRate                3047 non-null   float64\ndtypes: float64(29), int64(3), object(2)\nmemory usage: 809.5+ KB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "         avgAnnCount  avgDeathsPerYear  TARGET_deathRate  incidenceRate  \\\n",
       "count    3047.000000       3047.000000       3047.000000    3047.000000   \n",
       "unique           NaN               NaN               NaN            NaN   \n",
       "top              NaN               NaN               NaN            NaN   \n",
       "freq             NaN               NaN               NaN            NaN   \n",
       "mean      606.338544        185.965868        178.664063     448.268586   \n",
       "std      1416.356223        504.134286         27.751511      54.560733   \n",
       "min         6.000000          3.000000         59.700000     201.300000   \n",
       "25%        76.000000         28.000000        161.200000     420.300000   \n",
       "50%       171.000000         61.000000        178.100000     453.549422   \n",
       "75%       518.000000        149.000000        195.200000     480.850000   \n",
       "max     38150.000000      14010.000000        362.800000    1206.900000   \n",
       "\n",
       "            medIncome    popEst2015  povertyPercent  studyPerCap  \\\n",
       "count     3047.000000  3.047000e+03     3047.000000  3047.000000   \n",
       "unique            NaN           NaN             NaN          NaN   \n",
       "top               NaN           NaN             NaN          NaN   \n",
       "freq              NaN           NaN             NaN          NaN   \n",
       "mean     47063.281917  1.026374e+05       16.878175   155.399415   \n",
       "std      12040.090836  3.290592e+05        6.409087   529.628366   \n",
       "min      22640.000000  8.270000e+02        3.200000     0.000000   \n",
       "25%      38882.500000  1.168400e+04       12.150000     0.000000   \n",
       "50%      45207.000000  2.664300e+04       15.900000     0.000000   \n",
       "75%      52492.000000  6.867100e+04       20.400000    83.650776   \n",
       "max     125635.000000  1.017029e+07       47.400000  9762.308998   \n",
       "\n",
       "                 binnedInc    MedianAge  MedianAgeMale  MedianAgeFemale  \\\n",
       "count                 3047  3047.000000    3047.000000      3047.000000   \n",
       "unique                  10          NaN            NaN              NaN   \n",
       "top     (54545.6, 61494.5]          NaN            NaN              NaN   \n",
       "freq                   306          NaN            NaN              NaN   \n",
       "mean                   NaN    45.272333      39.570725        42.145323   \n",
       "std                    NaN    45.304480       5.226017         5.292849   \n",
       "min                    NaN    22.300000      22.400000        22.300000   \n",
       "25%                    NaN    37.700000      36.350000        39.100000   \n",
       "50%                    NaN    41.000000      39.600000        42.400000   \n",
       "75%                    NaN    44.000000      42.500000        45.300000   \n",
       "max                    NaN   624.000000      64.700000        65.700000   \n",
       "\n",
       "                            Geography  AvgHouseholdSize  PercentMarried  \\\n",
       "count                            3047       3047.000000     3047.000000   \n",
       "unique                           3047               NaN             NaN   \n",
       "top     Charles City County, Virginia               NaN             NaN   \n",
       "freq                                1               NaN             NaN   \n",
       "mean                              NaN          2.479662       51.773679   \n",
       "std                               NaN          0.429174        6.896928   \n",
       "min                               NaN          0.022100       23.100000   \n",
       "25%                               NaN          2.370000       47.750000   \n",
       "50%                               NaN          2.500000       52.400000   \n",
       "75%                               NaN          2.630000       56.400000   \n",
       "max                               NaN          3.970000       72.500000   \n",
       "\n",
       "        PctNoHS18_24   PctHS18_24  PctSomeCol18_24  PctBachDeg18_24  \\\n",
       "count    3047.000000  3047.000000       762.000000      3047.000000   \n",
       "unique           NaN          NaN              NaN              NaN   \n",
       "top              NaN          NaN              NaN              NaN   \n",
       "freq             NaN          NaN              NaN              NaN   \n",
       "mean       18.224450    35.002068        40.977034         6.158287   \n",
       "std         8.093064     9.069722        11.115805         4.529059   \n",
       "min         0.000000     0.000000         7.100000         0.000000   \n",
       "25%        12.800000    29.200000        34.000000         3.100000   \n",
       "50%        17.100000    34.700000        40.400000         5.400000   \n",
       "75%        22.700000    40.700000        46.400000         8.200000   \n",
       "max        64.100000    72.500000        79.000000        51.800000   \n",
       "\n",
       "        PctHS25_Over  PctBachDeg25_Over  PctEmployed16_Over  \\\n",
       "count    3047.000000        3047.000000         2895.000000   \n",
       "unique           NaN                NaN                 NaN   \n",
       "top              NaN                NaN                 NaN   \n",
       "freq             NaN                NaN                 NaN   \n",
       "mean       34.804660          13.282015           54.152642   \n",
       "std         7.034924           5.394756            8.315064   \n",
       "min         7.500000           2.500000           17.600000   \n",
       "25%        30.400000           9.400000           48.600000   \n",
       "50%        35.300000          12.300000           54.500000   \n",
       "75%        39.650000          16.100000           60.300000   \n",
       "max        54.800000          42.200000           80.100000   \n",
       "\n",
       "        PctUnemployed16_Over  PctPrivateCoverage  PctPrivateCoverageAlone  \\\n",
       "count            3047.000000         3047.000000              2438.000000   \n",
       "unique                   NaN                 NaN                      NaN   \n",
       "top                      NaN                 NaN                      NaN   \n",
       "freq                     NaN                 NaN                      NaN   \n",
       "mean                7.852412           64.354939                48.453774   \n",
       "std                 3.452371           10.647057                10.083006   \n",
       "min                 0.400000           22.300000                15.700000   \n",
       "25%                 5.500000           57.200000                41.000000   \n",
       "50%                 7.600000           65.100000                48.700000   \n",
       "75%                 9.700000           72.100000                55.600000   \n",
       "max                29.400000           92.300000                78.900000   \n",
       "\n",
       "        PctEmpPrivCoverage  PctPublicCoverage  PctPublicCoverageAlone  \\\n",
       "count          3047.000000        3047.000000             3047.000000   \n",
       "unique                 NaN                NaN                     NaN   \n",
       "top                    NaN                NaN                     NaN   \n",
       "freq                   NaN                NaN                     NaN   \n",
       "mean             41.196324          36.252642               19.240072   \n",
       "std               9.447687           7.841741                6.113041   \n",
       "min              13.500000          11.200000                2.600000   \n",
       "25%              34.500000          30.900000               14.850000   \n",
       "50%              41.100000          36.300000               18.800000   \n",
       "75%              47.700000          41.550000               23.100000   \n",
       "max              70.700000          65.100000               46.600000   \n",
       "\n",
       "           PctWhite     PctBlack     PctAsian  PctOtherRace  \\\n",
       "count   3047.000000  3047.000000  3047.000000   3047.000000   \n",
       "unique          NaN          NaN          NaN           NaN   \n",
       "top             NaN          NaN          NaN           NaN   \n",
       "freq            NaN          NaN          NaN           NaN   \n",
       "mean      83.645286     9.107978     1.253965      1.983523   \n",
       "std       16.380025    14.534538     2.610276      3.517710   \n",
       "min       10.199155     0.000000     0.000000      0.000000   \n",
       "25%       77.296180     0.620675     0.254199      0.295172   \n",
       "50%       90.059774     2.247576     0.549812      0.826185   \n",
       "75%       95.451693    10.509732     1.221037      2.177960   \n",
       "max      100.000000    85.947799    42.619425     41.930251   \n",
       "\n",
       "        PctMarriedHouseholds    BirthRate  \n",
       "count            3047.000000  3047.000000  \n",
       "unique                   NaN          NaN  \n",
       "top                      NaN          NaN  \n",
       "freq                     NaN          NaN  \n",
       "mean               51.243872     5.640306  \n",
       "std                 6.572814     1.985816  \n",
       "min                22.992490     0.000000  \n",
       "25%                47.763063     4.521419  \n",
       "50%                51.669941     5.381478  \n",
       "75%                55.395132     6.493677  \n",
       "max                78.075397    21.326165  "
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>avgAnnCount</th>\n      <th>avgDeathsPerYear</th>\n      <th>TARGET_deathRate</th>\n      <th>incidenceRate</th>\n      <th>medIncome</th>\n      <th>popEst2015</th>\n      <th>povertyPercent</th>\n      <th>studyPerCap</th>\n      <th>binnedInc</th>\n      <th>MedianAge</th>\n      <th>MedianAgeMale</th>\n      <th>MedianAgeFemale</th>\n      <th>Geography</th>\n      <th>AvgHouseholdSize</th>\n      <th>PercentMarried</th>\n      <th>PctNoHS18_24</th>\n      <th>PctHS18_24</th>\n      <th>PctSomeCol18_24</th>\n      <th>PctBachDeg18_24</th>\n      <th>PctHS25_Over</th>\n      <th>PctBachDeg25_Over</th>\n      <th>PctEmployed16_Over</th>\n      <th>PctUnemployed16_Over</th>\n      <th>PctPrivateCoverage</th>\n      <th>PctPrivateCoverageAlone</th>\n      <th>PctEmpPrivCoverage</th>\n      <th>PctPublicCoverage</th>\n      <th>PctPublicCoverageAlone</th>\n      <th>PctWhite</th>\n      <th>PctBlack</th>\n      <th>PctAsian</th>\n      <th>PctOtherRace</th>\n      <th>PctMarriedHouseholds</th>\n      <th>BirthRate</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>count</th>\n      <td>3047.000000</td>\n      <td>3047.000000</td>\n      <td>3047.000000</td>\n      <td>3047.000000</td>\n      <td>3047.000000</td>\n      <td>3.047000e+03</td>\n      <td>3047.000000</td>\n      <td>3047.000000</td>\n      <td>3047</td>\n      <td>3047.000000</td>\n      <td>3047.000000</td>\n      <td>3047.000000</td>\n      <td>3047</td>\n      <td>3047.000000</td>\n      <td>3047.000000</td>\n      <td>3047.000000</td>\n      <td>3047.000000</td>\n      <td>762.000000</td>\n      <td>3047.000000</td>\n      <td>3047.000000</td>\n      <td>3047.000000</td>\n      <td>2895.000000</td>\n      <td>3047.000000</td>\n      <td>3047.000000</td>\n      <td>2438.000000</td>\n      <td>3047.000000</td>\n      <td>3047.000000</td>\n      <td>3047.000000</td>\n      <td>3047.000000</td>\n      <td>3047.000000</td>\n      <td>3047.000000</td>\n      <td>3047.000000</td>\n      <td>3047.000000</td>\n      <td>3047.000000</td>\n    </tr>\n    <tr>\n      <th>unique</th>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>10</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>3047</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>top</th>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>(54545.6, 61494.5]</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>Charles City County, Virginia</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>freq</th>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>306</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>1</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>mean</th>\n      <td>606.338544</td>\n      <td>185.965868</td>\n      <td>178.664063</td>\n      <td>448.268586</td>\n      <td>47063.281917</td>\n      <td>1.026374e+05</td>\n      <td>16.878175</td>\n      <td>155.399415</td>\n      <td>NaN</td>\n      <td>45.272333</td>\n      <td>39.570725</td>\n      <td>42.145323</td>\n      <td>NaN</td>\n      <td>2.479662</td>\n      <td>51.773679</td>\n      <td>18.224450</td>\n      <td>35.002068</td>\n      <td>40.977034</td>\n      <td>6.158287</td>\n      <td>34.804660</td>\n      <td>13.282015</td>\n      <td>54.152642</td>\n      <td>7.852412</td>\n      <td>64.354939</td>\n      <td>48.453774</td>\n      <td>41.196324</td>\n      <td>36.252642</td>\n      <td>19.240072</td>\n      <td>83.645286</td>\n      <td>9.107978</td>\n      <td>1.253965</td>\n      <td>1.983523</td>\n      <td>51.243872</td>\n      <td>5.640306</td>\n    </tr>\n    <tr>\n      <th>std</th>\n      <td>1416.356223</td>\n      <td>504.134286</td>\n      <td>27.751511</td>\n      <td>54.560733</td>\n      <td>12040.090836</td>\n      <td>3.290592e+05</td>\n      <td>6.409087</td>\n      <td>529.628366</td>\n      <td>NaN</td>\n      <td>45.304480</td>\n      <td>5.226017</td>\n      <td>5.292849</td>\n      <td>NaN</td>\n      <td>0.429174</td>\n      <td>6.896928</td>\n      <td>8.093064</td>\n      <td>9.069722</td>\n      <td>11.115805</td>\n      <td>4.529059</td>\n      <td>7.034924</td>\n      <td>5.394756</td>\n      <td>8.315064</td>\n      <td>3.452371</td>\n      <td>10.647057</td>\n      <td>10.083006</td>\n      <td>9.447687</td>\n      <td>7.841741</td>\n      <td>6.113041</td>\n      <td>16.380025</td>\n      <td>14.534538</td>\n      <td>2.610276</td>\n      <td>3.517710</td>\n      <td>6.572814</td>\n      <td>1.985816</td>\n    </tr>\n    <tr>\n      <th>min</th>\n      <td>6.000000</td>\n      <td>3.000000</td>\n      <td>59.700000</td>\n      <td>201.300000</td>\n      <td>22640.000000</td>\n      <td>8.270000e+02</td>\n      <td>3.200000</td>\n      <td>0.000000</td>\n      <td>NaN</td>\n      <td>22.300000</td>\n      <td>22.400000</td>\n      <td>22.300000</td>\n      <td>NaN</td>\n      <td>0.022100</td>\n      <td>23.100000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>7.100000</td>\n      <td>0.000000</td>\n      <td>7.500000</td>\n      <td>2.500000</td>\n      <td>17.600000</td>\n      <td>0.400000</td>\n      <td>22.300000</td>\n      <td>15.700000</td>\n      <td>13.500000</td>\n      <td>11.200000</td>\n      <td>2.600000</td>\n      <td>10.199155</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>22.992490</td>\n      <td>0.000000</td>\n    </tr>\n    <tr>\n      <th>25%</th>\n      <td>76.000000</td>\n      <td>28.000000</td>\n      <td>161.200000</td>\n      <td>420.300000</td>\n      <td>38882.500000</td>\n      <td>1.168400e+04</td>\n      <td>12.150000</td>\n      <td>0.000000</td>\n      <td>NaN</td>\n      <td>37.700000</td>\n      <td>36.350000</td>\n      <td>39.100000</td>\n      <td>NaN</td>\n      <td>2.370000</td>\n      <td>47.750000</td>\n      <td>12.800000</td>\n      <td>29.200000</td>\n      <td>34.000000</td>\n      <td>3.100000</td>\n      <td>30.400000</td>\n      <td>9.400000</td>\n      <td>48.600000</td>\n      <td>5.500000</td>\n      <td>57.200000</td>\n      <td>41.000000</td>\n      <td>34.500000</td>\n      <td>30.900000</td>\n      <td>14.850000</td>\n      <td>77.296180</td>\n      <td>0.620675</td>\n      <td>0.254199</td>\n      <td>0.295172</td>\n      <td>47.763063</td>\n      <td>4.521419</td>\n    </tr>\n    <tr>\n      <th>50%</th>\n      <td>171.000000</td>\n      <td>61.000000</td>\n      <td>178.100000</td>\n      <td>453.549422</td>\n      <td>45207.000000</td>\n      <td>2.664300e+04</td>\n      <td>15.900000</td>\n      <td>0.000000</td>\n      <td>NaN</td>\n      <td>41.000000</td>\n      <td>39.600000</td>\n      <td>42.400000</td>\n      <td>NaN</td>\n      <td>2.500000</td>\n      <td>52.400000</td>\n      <td>17.100000</td>\n      <td>34.700000</td>\n      <td>40.400000</td>\n      <td>5.400000</td>\n      <td>35.300000</td>\n      <td>12.300000</td>\n      <td>54.500000</td>\n      <td>7.600000</td>\n      <td>65.100000</td>\n      <td>48.700000</td>\n      <td>41.100000</td>\n      <td>36.300000</td>\n      <td>18.800000</td>\n      <td>90.059774</td>\n      <td>2.247576</td>\n      <td>0.549812</td>\n      <td>0.826185</td>\n      <td>51.669941</td>\n      <td>5.381478</td>\n    </tr>\n    <tr>\n      <th>75%</th>\n      <td>518.000000</td>\n      <td>149.000000</td>\n      <td>195.200000</td>\n      <td>480.850000</td>\n      <td>52492.000000</td>\n      <td>6.867100e+04</td>\n      <td>20.400000</td>\n      <td>83.650776</td>\n      <td>NaN</td>\n      <td>44.000000</td>\n      <td>42.500000</td>\n      <td>45.300000</td>\n      <td>NaN</td>\n      <td>2.630000</td>\n      <td>56.400000</td>\n      <td>22.700000</td>\n      <td>40.700000</td>\n      <td>46.400000</td>\n      <td>8.200000</td>\n      <td>39.650000</td>\n      <td>16.100000</td>\n      <td>60.300000</td>\n      <td>9.700000</td>\n      <td>72.100000</td>\n      <td>55.600000</td>\n      <td>47.700000</td>\n      <td>41.550000</td>\n      <td>23.100000</td>\n      <td>95.451693</td>\n      <td>10.509732</td>\n      <td>1.221037</td>\n      <td>2.177960</td>\n      <td>55.395132</td>\n      <td>6.493677</td>\n    </tr>\n    <tr>\n      <th>max</th>\n      <td>38150.000000</td>\n      <td>14010.000000</td>\n      <td>362.800000</td>\n      <td>1206.900000</td>\n      <td>125635.000000</td>\n      <td>1.017029e+07</td>\n      <td>47.400000</td>\n      <td>9762.308998</td>\n      <td>NaN</td>\n      <td>624.000000</td>\n      <td>64.700000</td>\n      <td>65.700000</td>\n      <td>NaN</td>\n      <td>3.970000</td>\n      <td>72.500000</td>\n      <td>64.100000</td>\n      <td>72.500000</td>\n      <td>79.000000</td>\n      <td>51.800000</td>\n      <td>54.800000</td>\n      <td>42.200000</td>\n      <td>80.100000</td>\n      <td>29.400000</td>\n      <td>92.300000</td>\n      <td>78.900000</td>\n      <td>70.700000</td>\n      <td>65.100000</td>\n      <td>46.600000</td>\n      <td>100.000000</td>\n      <td>85.947799</td>\n      <td>42.619425</td>\n      <td>41.930251</td>\n      <td>78.075397</td>\n      <td>21.326165</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 4
    }
   ],
   "source": [
    "df.describe(include='all')"
   ]
  },
  {
   "source": [
    "## Data Processing\n",
    "As we are using only numeric features, we will drop out Geography and binnedInc columns."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_cleaned = df.copy()\n",
    "df_cleaned = df_cleaned.drop(columns=['Geography','binnedInc'])"
   ]
  },
  {
   "source": [
    "## Run Linear Regression\n",
    "Run the univariant linear regression on state against TARGET_deathRate. \n",
    "\n",
    "Then print out the score and MSE, and also draw the diagram of ground truth and prediction model."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "### Create getScore(X,y) method for reuse\n",
    "Set up a method to split the preprocessed data into training (80%) and testing (20%) set, and then run linear regression on the training set while printing out the R Square score and MSE using the testing set."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_squared_error as mse\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "def getScore(X,y):\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state = 0)\n",
    "    reg = LinearRegression()\n",
    "    reg.fit(X_train,y_train)\n",
    "    print(\"Score is %.4f\" % reg.score(X_test,y_test))\n",
    "    print(\"Training set MSE is %.4f\" % mse(y_train, reg.predict(X_train)))\n",
    "    print(\"Testing set MSE is %.4f\" % mse(y_test, reg.predict(X_test)))\n",
    "    return reg.score(X_test,y_test)\n"
   ]
  },
  {
   "source": [
    "### Drop all missing data and try to see the result\n",
    "See the baseline without any further pre-processing"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Score is 0.3013\nTraining set MSE is 363.2677\nTesting set MSE is 529.6852\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "0.30125046110409215"
      ]
     },
     "metadata": {},
     "execution_count": 7
    }
   ],
   "source": [
    "df_proc = df_cleaned.dropna(how='any')\n",
    "X = df_proc.drop(columns='TARGET_deathRate').values\n",
    "y = df_proc['TARGET_deathRate']\n",
    "\n",
    "getScore(X,y)"
   ]
  },
  {
   "source": [
    "### Clean up unreasonable data\n",
    "By quickly review the data, we noticed that \n",
    "* MedianAge has number larger than 100, which is probably a typo and should be divided by 10. \n",
    "* AvgHouseholdSize has value smaller than 1, which is probably a typo and should be multiplied by 100."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "df_cleaned.AvgHouseholdSize = df_cleaned.AvgHouseholdSize.apply(lambda x: x if x > 1 else x*100)\n",
    "df_cleaned.MedianAge = df_cleaned.MedianAge.apply(lambda x: x if x < 100 else x/10)"
   ],
   "cell_type": "code",
   "metadata": {},
   "execution_count": 8,
   "outputs": []
  },
  {
   "source": [
    "### Rerun the baseline\n",
    "The expectation here is the result should be better as included data is more accurate and meaningful."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Score is 0.3066\nTraining set MSE is 364.7068\nTesting set MSE is 525.6571\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "0.30656420507535764"
      ]
     },
     "metadata": {},
     "execution_count": 9
    }
   ],
   "source": [
    "df_proc = df_cleaned.dropna(how='any')\n",
    "X = df_proc.drop(columns='TARGET_deathRate').values\n",
    "y = df_proc['TARGET_deathRate']\n",
    "\n",
    "getScore(X,y)"
   ]
  },
  {
   "source": [
    "### Too many missing data for feature - PctSomeCol18_24"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Score is 0.4490\nTraining set MSE is 367.9426\nTesting set MSE is 416.9053\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "0.44900944584382485"
      ]
     },
     "metadata": {},
     "execution_count": 10
    }
   ],
   "source": [
    "# PctSomeCol18_24 only has 25% meaningful data. Try Removing this column completely.\n",
    "df_proc = df_cleaned.copy()\n",
    "df_proc = df_proc.drop(columns='PctSomeCol18_24').dropna(how='any')\n",
    "X = df_proc.drop(columns='TARGET_deathRate').values\n",
    "y = df_proc['TARGET_deathRate']\n",
    "getScore(X,y)"
   ]
  },
  {
   "source": [
    "Try manipulate PctSomeCol18_24 to use average for missing data\n",
    "\n",
    "Define replaceMissingWithMean(df, feature) for reuse"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def replaceMissingWithMean(df, feature):\n",
    "    mean = df.dropna(how='any', subset=[feature])[feature].mean()\n",
    "    df[feature].fillna(value=mean, inplace=True)\n",
    "    df.dropna(how='any', inplace=True)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Score is 0.4487\nTraining set MSE is 367.9406\nTesting set MSE is 417.1099\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "0.44873907546643754"
      ]
     },
     "metadata": {},
     "execution_count": 12
    }
   ],
   "source": [
    "# Try replacing missing value with mean\n",
    "df_proc = df_cleaned.copy()\n",
    "df_proc = replaceMissingWithMean(df_proc, 'PctSomeCol18_24')\n",
    "X = df_proc.drop(columns='TARGET_deathRate').values\n",
    "y = df_proc['TARGET_deathRate']\n",
    "getScore(X,y)"
   ]
  },
  {
   "source": [
    "Define replaceMissingWithMedian(df, feature) for reuse"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def replaceMissingWithMedian(df, feature):\n",
    "    median = df.dropna(how='any', subset=[feature])[feature].median()\n",
    "    df[feature].fillna(value=median, inplace=True)\n",
    "    df.dropna(how='any', inplace=True)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Score is 0.4487\nTraining set MSE is 367.9394\nTesting set MSE is 417.1596\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "0.44867337554465336"
      ]
     },
     "metadata": {},
     "execution_count": 14
    }
   ],
   "source": [
    "# Try replacing missing value with median\n",
    "df_proc = df_cleaned.copy()\n",
    "df_proc = replaceMissingWithMedian(df_proc, 'PctSomeCol18_24')\n",
    "X = df_proc.drop(columns='TARGET_deathRate').values\n",
    "y = df_proc['TARGET_deathRate']\n",
    "getScore(X,y)"
   ]
  },
  {
   "source": [
    "The performance is about the same between deleting this feature and replacing with mean or median value. Remove this feature"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "### Handle next feature with missing value - PctPrivateCoverageAlone"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Score is 0.4869\nTraining set MSE is 365.7441\nTesting set MSE is 384.5184\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "0.48686780406878805"
      ]
     },
     "metadata": {},
     "execution_count": 15
    }
   ],
   "source": [
    "# Try removing the feature completely and see the performance\n",
    "df_proc = df_cleaned.copy()\n",
    "df_proc = df_proc.drop(columns=['PctSomeCol18_24','PctPrivateCoverageAlone']).dropna(how='any')\n",
    "X = df_proc.drop(columns='TARGET_deathRate').values\n",
    "y = df_proc['TARGET_deathRate']\n",
    "getScore(X,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Score is 0.4873\nTraining set MSE is 365.7100\nTesting set MSE is 384.2174\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "0.4872695535129641"
      ]
     },
     "metadata": {},
     "execution_count": 16
    }
   ],
   "source": [
    "# Try replacing missing value with mean\n",
    "df_proc = df_cleaned.copy()\n",
    "df_proc = df_proc.drop(columns=['PctSomeCol18_24'])\n",
    "df_proc = replaceMissingWithMean(df_proc, 'PctPrivateCoverageAlone')\n",
    "X = df_proc.drop(columns='TARGET_deathRate').values\n",
    "y = df_proc['TARGET_deathRate']\n",
    "getScore(X,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Score is 0.4873\n",
      "Training set MSE is 365.7098\n",
      "Testing set MSE is 384.2158\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "0.48727161448240575"
      ]
     },
     "metadata": {},
     "execution_count": 17
    }
   ],
   "source": [
    "# Try replacing missing value with median\n",
    "df_proc = df_cleaned.copy()\n",
    "df_proc = df_proc.drop(columns=['PctSomeCol18_24'])\n",
    "df_proc = replaceMissingWithMedian(df_proc, 'PctPrivateCoverageAlone')\n",
    "X = df_proc.drop(columns='TARGET_deathRate').values\n",
    "y = df_proc['TARGET_deathRate']\n",
    "getScore(X,y)"
   ]
  },
  {
   "source": [
    "The performance is about the same between deleting this feature and replacing with mean or median value."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "### Handle next feature with missing value - PctEmployed16_Over"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Score is 0.5640\n",
      "Training set MSE is 376.0007\n",
      "Testing set MSE is 343.9928\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "0.5639999062278332"
      ]
     },
     "metadata": {},
     "execution_count": 18
    }
   ],
   "source": [
    "# Try removing the feature completely\n",
    "df_proc = df_cleaned.copy()\n",
    "df_proc = df_proc.drop(columns=['PctSomeCol18_24','PctPrivateCoverageAlone','PctEmployed16_Over']).dropna(how='any')\n",
    "X = df_proc.drop(columns='TARGET_deathRate').values\n",
    "y = df_proc['TARGET_deathRate']\n",
    "getScore(X,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Score is 0.5636\nTraining set MSE is 372.6659\nTesting set MSE is 344.2809\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "0.5636348386287059"
      ]
     },
     "metadata": {},
     "execution_count": 19
    }
   ],
   "source": [
    "# Replacing missing value with mean\n",
    "df_proc = df_cleaned.copy()\n",
    "df_proc = df_proc.drop(columns=['PctSomeCol18_24','PctPrivateCoverageAlone'])\n",
    "df_proc = replaceMissingWithMean(df_proc, 'PctEmployed16_Over')\n",
    "X = df_proc.drop(columns='TARGET_deathRate').values\n",
    "y = df_proc['TARGET_deathRate']\n",
    "getScore(X,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Score is 0.5636\nTraining set MSE is 372.6756\nTesting set MSE is 344.2759\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "0.5636410786374628"
      ]
     },
     "metadata": {},
     "execution_count": 20
    }
   ],
   "source": [
    "# Replacing missing value with median\n",
    "df_proc = df_cleaned.copy()\n",
    "df_proc = df_proc.drop(columns=['PctSomeCol18_24','PctPrivateCoverageAlone'])\n",
    "df_proc = replaceMissingWithMedian(df_proc, 'PctEmployed16_Over')\n",
    "X = df_proc.drop(columns='TARGET_deathRate').values\n",
    "y = df_proc['TARGET_deathRate']\n",
    "getScore(X,y)"
   ]
  },
  {
   "source": [
    "The performance is about the same between deleting this feature and replacing with mean value."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "### Lots of 0 value in feature - studyPerCap\n",
    "Although studyPerCap feature does not have missing value, there are lots of 0 in this feature. Treat the value 0 as missing value. Only about 30% of data has meaningful value for this feature."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "(1116, 30)"
      ]
     },
     "metadata": {},
     "execution_count": 21
    }
   ],
   "source": [
    "df_proc[df_proc.studyPerCap != 0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Score is 0.5640\n",
      "Training set MSE is 376.0020\n",
      "Testing set MSE is 343.9717\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "0.5640266487236938"
      ]
     },
     "metadata": {},
     "execution_count": 22
    }
   ],
   "source": [
    "# Remove this feature completely\n",
    "df_proc = df_cleaned.copy()\n",
    "df_proc = df_proc.drop(columns=['PctSomeCol18_24','PctPrivateCoverageAlone','PctEmployed16_Over','studyPerCap']).dropna(how='any')\n",
    "X = df_proc.drop(columns='TARGET_deathRate').values\n",
    "y = df_proc['TARGET_deathRate']\n",
    "getScore(X,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Score is 0.5642\nTraining set MSE is 375.9639\nTesting set MSE is 343.8452\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "0.5641870032538023"
      ]
     },
     "metadata": {},
     "execution_count": 23
    }
   ],
   "source": [
    "# Try replacing 0 with mean\n",
    "df_proc = df_cleaned.copy()\n",
    "df_proc = df_proc.drop(columns=['PctSomeCol18_24','PctPrivateCoverageAlone','PctEmployed16_Over']).dropna(how='any')\n",
    "\n",
    "mean = df_proc[df_proc.studyPerCap != 0].studyPerCap.mean()\n",
    "df_proc.studyPerCap.replace(to_replace=0, value=mean, inplace=True)\n",
    "X = df_proc.drop(columns='TARGET_deathRate').values\n",
    "y = df_proc['TARGET_deathRate']\n",
    "getScore(X,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Score is 0.5226\nTraining set MSE is 190.7173\nTesting set MSE is 282.8436\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "0.5226133010304227"
      ]
     },
     "metadata": {},
     "execution_count": 24
    }
   ],
   "source": [
    "# Try dropping missing value rows\n",
    "df_proc = df_cleaned.copy()\n",
    "df_proc = df_proc.drop(columns=['PctSomeCol18_24','PctPrivateCoverageAlone','PctEmployed16_Over']).dropna(how='any')\n",
    "df_proc = df_proc[df_proc.studyPerCap != 0]\n",
    "X = df_proc.drop(columns='TARGET_deathRate').values\n",
    "y = df_proc['TARGET_deathRate']\n",
    "getScore(X,y)"
   ]
  },
  {
   "source": [
    "The performance has greatly improved, but it can be due to the much lesser amount of data. It is something worth exploring in the future."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "### Lots of duplicate value in feature - avgAnnCount\n",
    "Although avgAnnCount feature does not have missing value, there are lots of 1962.667684 in this feature. Treat the value 1962.667684 as missing value. Around 30% of data has meaningful avgAnnCount."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "(1058, 29)"
      ]
     },
     "metadata": {},
     "execution_count": 25
    }
   ],
   "source": [
    "df_proc[df_proc.avgAnnCount != 1962.667684].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Score is 0.5432\n",
      "Training set MSE is 356.9329\n",
      "Testing set MSE is 313.1803\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "0.5432403559785393"
      ]
     },
     "metadata": {},
     "execution_count": 26
    }
   ],
   "source": [
    "# Removing those missing value rows\n",
    "df_dropna = df_cleaned.copy()\n",
    "df_dropna = df_dropna.drop(columns=['PctSomeCol18_24','PctPrivateCoverageAlone','PctEmployed16_Over','studyPerCap']).dropna(how='any')\n",
    "df_dropna = df_dropna[df_dropna.avgAnnCount != 1962.667684]\n",
    "X = df_dropna.drop(columns='TARGET_deathRate').values\n",
    "y = df_dropna['TARGET_deathRate']\n",
    "getScore(X,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Score is 0.5609\nTraining set MSE is 378.5052\nTesting set MSE is 346.4604\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "0.5608723551353566"
      ]
     },
     "metadata": {},
     "execution_count": 27
    }
   ],
   "source": [
    "# Delete this feature completely\n",
    "df_dropna = df_cleaned.copy()\n",
    "df_dropna = df_dropna.drop(columns=['PctSomeCol18_24','PctPrivateCoverageAlone','PctEmployed16_Over','studyPerCap','avgAnnCount']).dropna(how='any')\n",
    "X = df_dropna.drop(columns='TARGET_deathRate').values\n",
    "y = df_dropna['TARGET_deathRate']\n",
    "getScore(X,y)"
   ]
  },
  {
   "source": [
    "The performance is about the same"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "### Lot of value 453.5494221 for feature - incidenceRate\n"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Score is 0.5109\nTraining set MSE is 370.8431\nTesting set MSE is 335.3327\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "0.5109320689101766"
      ]
     },
     "metadata": {},
     "execution_count": 28
    }
   ],
   "source": [
    "# Removing those missing rows\n",
    "df_dropna = df_cleaned.copy()\n",
    "df_dropna = df_dropna.drop(columns=['PctSomeCol18_24','PctPrivateCoverageAlone','PctEmployed16_Over','studyPerCap','avgAnnCount']).dropna(how='any')\n",
    "df_dropna = df_dropna[df_dropna.incidenceRate != 453.5494221]\n",
    "X = df_dropna.drop(columns='TARGET_deathRate').values\n",
    "y = df_dropna['TARGET_deathRate']\n",
    "getScore(X,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Score is 0.4254\nTraining set MSE is 456.7620\nTesting set MSE is 453.3053\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "0.4254497990969408"
      ]
     },
     "metadata": {},
     "execution_count": 29
    }
   ],
   "source": [
    "# Try removing this feature completely\n",
    "df_dropna = df_cleaned.copy()\n",
    "df_dropna = df_dropna.drop(columns=['PctSomeCol18_24','PctPrivateCoverageAlone','PctEmployed16_Over','studyPerCap','avgAnnCount','incidenceRate']).dropna(how='any')\n",
    "X = df_dropna.drop(columns='TARGET_deathRate').values\n",
    "y = df_dropna['TARGET_deathRate']\n",
    "getScore(X,y)"
   ]
  },
  {
   "source": [
    "The performance has dropped significantly, so this feature is quite important in the prediction model."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Score is 0.5615\n",
      "Training set MSE is 378.1749\n",
      "Testing set MSE is 346.0027\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "0.5614524339573921"
      ]
     },
     "metadata": {},
     "execution_count": 30
    }
   ],
   "source": [
    "# Try replacing the dummy value with the mean\n",
    "df_dropna = df_cleaned.copy()\n",
    "df_dropna = df_dropna.drop(columns=['PctSomeCol18_24','PctPrivateCoverageAlone','PctEmployed16_Over','studyPerCap','avgAnnCount']).dropna(how='any')\n",
    "mean = df_dropna[df_dropna.incidenceRate != 453.5494221].incidenceRate.mean()\n",
    "df_dropna['incidenceRate'].replace(to_replace=453.5494221, value=mean, inplace=True)\n",
    "X = df_dropna.drop(columns='TARGET_deathRate').values\n",
    "y = df_dropna['TARGET_deathRate']\n",
    "getScore(X,y)\n"
   ]
  },
  {
   "source": [
    "The final value has been consistent across previous cells\n",
    "\n",
    "Score is 0.5615\n",
    "\n",
    "Training set MSE is 378.1749\n",
    "\n",
    "Testing set MSE is 346.0027"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Score is 0.5238\nTraining set MSE is 300.6347\nTesting set MSE is 375.7230\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "0.5237828825983781"
      ]
     },
     "metadata": {},
     "execution_count": 47
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "def getScoreRT(X,y):\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state = 0)\n",
    "    reg = RandomForestRegressor(n_estimators = 100, max_depth=5, min_samples_leaf=2, min_samples_split=2, random_state = 0)\n",
    "    reg.fit(X_train,y_train)\n",
    "    print(\"Score is %.4f\" % reg.score(X_test,y_test))\n",
    "    print(\"Training set MSE is %.4f\" % mse(y_train, reg.predict(X_train)))\n",
    "    print(\"Testing set MSE is %.4f\" % mse(y_test, reg.predict(X_test)))\n",
    "    return reg.score(X_test,y_test)\n",
    "getScoreRT(X,y)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "RandomForestRegressor(n_estimators=10, random_state=0)"
      ]
     },
     "metadata": {},
     "execution_count": 31
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "regressor = RandomForestRegressor(n_estimators = 10, random_state = 0)\n",
    "regressor.fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Score is 0.5118\nTraining set MSE is 72.2623\nTesting set MSE is 385.1399\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "0.5118473069868028"
      ]
     },
     "metadata": {},
     "execution_count": 36
    }
   ],
   "source": [
    "getScoreRT(X,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "y_array = y.values\n",
    "y_2d = y_array.reshape(len(y_array),1)\n",
    "sc_X = StandardScaler()\n",
    "sc_y = StandardScaler()\n",
    "Xsc = sc_X.fit_transform(X)\n",
    "ysc = sc_y.fit_transform(y_2d)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Score is 0.6489\n",
      "Training set MSE is 0.3251\n",
      "Testing set MSE is 0.3598\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "0.6489281691761573"
      ]
     },
     "metadata": {},
     "execution_count": 61
    }
   ],
   "source": [
    "from sklearn.svm import SVR\n",
    "\n",
    "def getScoreSVM(X,y):\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state = 0)\n",
    "    reg = SVR(kernel = 'rbf')\n",
    "    reg.fit(X, y)\n",
    "    reg.fit(X, y)\n",
    "    print(\"Score is %.4f\" % reg.score(X_test,y_test))\n",
    "    print(\"Training set MSE is %.4f\" % mse(y_train, reg.predict(X_train)))\n",
    "    print(\"Testing set MSE is %.4f\" % mse(y_test, reg.predict(X_test)))\n",
    "    return reg.score(X_test,y_test)\n",
    "getScoreSVM(Xsc,ysc)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Score is 0.5608\n",
      "Training set MSE is 378.4930\n",
      "Testing set MSE is 346.5180\n",
      "Score is 0.5622\n",
      "Training set MSE is 379.1588\n",
      "Testing set MSE is 345.3914\n",
      "Score is 0.4261\n",
      "Training set MSE is 455.6572\n",
      "Testing set MSE is 452.8194\n",
      "Score is 0.5648\n",
      "Training set MSE is 376.6097\n",
      "Testing set MSE is 343.3886\n",
      "Score is 0.5650\n",
      "Training set MSE is 377.3284\n",
      "Testing set MSE is 343.1759\n",
      "popEst2015\n",
      "Score is 0.5630\n",
      "Training set MSE is 377.7241\n",
      "Testing set MSE is 344.7507\n",
      "Score is 0.5640\n",
      "Training set MSE is 376.0020\n",
      "Testing set MSE is 343.9717\n",
      "Score is 0.5642\n",
      "Training set MSE is 376.0308\n",
      "Testing set MSE is 343.8681\n",
      "Score is 0.5639\n",
      "Training set MSE is 376.2066\n",
      "Testing set MSE is 344.0774\n",
      "Score is 0.5640\n",
      "Training set MSE is 376.0008\n",
      "Testing set MSE is 343.9650\n",
      "Score is 0.5591\n",
      "Training set MSE is 377.0097\n",
      "Testing set MSE is 347.8372\n",
      "Score is 0.5640\n",
      "Training set MSE is 378.0870\n",
      "Testing set MSE is 343.9797\n",
      "Score is 0.5624\n",
      "Training set MSE is 376.2795\n",
      "Testing set MSE is 345.2868\n",
      "Score is 0.5575\n",
      "Training set MSE is 378.7465\n",
      "Testing set MSE is 349.1273\n",
      "Score is 0.5644\n",
      "Training set MSE is 376.1568\n",
      "Testing set MSE is 343.6702\n",
      "Score is 0.5633\n",
      "Training set MSE is 378.1340\n",
      "Testing set MSE is 344.5690\n",
      "Score is 0.5468\n",
      "Training set MSE is 383.8442\n",
      "Testing set MSE is 357.5664\n",
      "Score is 0.5635\n",
      "Training set MSE is 377.1336\n",
      "Testing set MSE is 344.3584\n",
      "Score is 0.5577\n",
      "Training set MSE is 377.8177\n",
      "Testing set MSE is 348.9464\n",
      "Score is 0.5602\n",
      "Training set MSE is 376.5283\n",
      "Testing set MSE is 346.9861\n",
      "Score is 0.5650\n",
      "Training set MSE is 376.1211\n",
      "Testing set MSE is 343.1686\n",
      "PctPublicCoverage\n",
      "Score is 0.5650\n",
      "Training set MSE is 376.1555\n",
      "Testing set MSE is 343.2019\n",
      "PctPublicCoverageAlone\n",
      "Score is 0.5607\n",
      "Training set MSE is 376.5643\n",
      "Testing set MSE is 346.5659\n",
      "Score is 0.5636\n",
      "Training set MSE is 376.2430\n",
      "Testing set MSE is 344.2937\n",
      "Score is 0.5650\n",
      "Training set MSE is 376.0802\n",
      "Testing set MSE is 343.2148\n",
      "Score is 0.5572\n",
      "Training set MSE is 382.5744\n",
      "Testing set MSE is 349.3212\n",
      "Score is 0.5676\n",
      "Training set MSE is 377.7844\n",
      "Testing set MSE is 341.1870\n",
      "PctMarriedHouseholds\n",
      "Score is 0.5594\n",
      "Training set MSE is 378.3812\n",
      "Testing set MSE is 347.5868\n"
     ]
    }
   ],
   "source": [
    "df_dropna = df_cleaned.copy()\n",
    "df_dropna = df_dropna.drop(columns=['PctSomeCol18_24','PctPrivateCoverageAlone','PctEmployed16_Over'])\n",
    "features = df_dropna.columns\n",
    "\n",
    "for f in features:\n",
    "    if f != 'TARGET_deathRate':\n",
    "        df_dropna = df_cleaned.copy()\n",
    "        df_dropna = df_dropna.drop(columns=['PctSomeCol18_24','PctPrivateCoverageAlone','PctEmployed16_Over',f]).dropna(how='any')\n",
    "        X = df_dropna.drop(columns='TARGET_deathRate').values\n",
    "        y = df_dropna['TARGET_deathRate']\n",
    "        score = getScore(X,y)\n",
    "        if score >= 0.5650:\n",
    "            print(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Score is 0.5660\nTraining set MSE is 382.2834\nTesting set MSE is 342.4393\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "0.565968989229412"
      ]
     },
     "metadata": {},
     "execution_count": 38
    }
   ],
   "source": [
    "# Try replacing the dummy value with the mean\n",
    "df_dropna = df_cleaned.copy()\n",
    "df_dropna = df_dropna.drop(columns=['PctSomeCol18_24','PctPrivateCoverageAlone','PctEmployed16_Over','avgAnnCount','avgDeathsPerYear','medIncome','popEst2015','PctPublicCoverage','PctPublicCoverageAlone','PctMarriedHouseholds']).dropna(how='any')\n",
    "X = df_dropna.drop(columns='TARGET_deathRate').values\n",
    "y = df_dropna['TARGET_deathRate']\n",
    "getScore(X,y)\n"
   ]
  }
 ]
}